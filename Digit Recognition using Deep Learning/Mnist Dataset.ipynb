{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7801ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#Data Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d63085",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "489d34a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56be4390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOJElEQVR4nO3dbYxc5XnG8evC2AYMaWyoXRcMIcG8NaUmXQENVQvipQSpMSShwqkiVyJ1QJCGKqilVBX+QCXUQhBFaYoTLJuWQFIRhNXQEsdFoFSNw4IMmDpgggwYWzYvAptS7PX67oc9RAvseWY9c+bF3P+ftJqZc8+Zc2u0157Zec45jyNCAD78Duh3AwB6g7ADSRB2IAnCDiRB2IEkDuzlxqZ5ehykGb3cJJDKO/pf7Y5dnqjWUdhtXyDpVklTJH0nIm4sPf8gzdDpPqeTTQIoWBtramttf4y3PUXSNyV9RtLJkhbZPrnd1wPQXZ38z36apOci4vmI2C3pHkkLm2kLQNM6CfuRkl4a93hztew9bC+xPWx7eES7OtgcgE50EvaJvgT4wLG3EbEsIoYiYmiqpnewOQCd6CTsmyXNG/f4KElbOmsHQLd0EvZHJc23faztaZIulbSqmbYANK3tobeI2GP7KkkPamzobXlEPN1YZwAa1dE4e0Q8IOmBhnoB0EUcLgskQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IoqMpm21vkrRT0qikPREx1ERTAJrXUdgrZ0fEqw28DoAu4mM8kESnYQ9JP7L9mO0lEz3B9hLbw7aHR7Srw80BaFenH+PPjIgttmdLWm375xHxyPgnRMQyScsk6SOeFR1uD0CbOtqzR8SW6na7pPskndZEUwCa13bYbc+wfdi79yWdL2l9U40BaFYnH+PnSLrP9ruv892I+I9GugLQuLbDHhHPS/qtBnsB0EUMvQFJEHYgCcIOJEHYgSQIO5BEEyfCYIDt/oPyiYgv/PHeYv2KTz1crF8989l97uldv/mdrxbrh2wtH3D5xqfLh18fc1f9vmzag8PFdT+M2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs38IvHL579TWbvuLbxbXHZo+Wqwf0GJ/sHjTucX6qb/yYm3tiS/fWly3lVa9fXrWotrarAc72vR+iT07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPsA8NRpxfo755Yv4nvvX/19be3XD5xeXPeyF84r1l+46YRifcYP1xXrDx1ydG3t4fuOL6577/xVxXorO9YdXlub1dEr75/YswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzD4CtV5Wv7f6za1qd910/ln7Jc39YXHPP50eK9UNeXVusl6/sLm1Z8tu1tbXzOzuf/d/fPqxYP+72l2prezra8v6p5Z7d9nLb222vH7dslu3VtjdWtzO72yaATk3mY/wKSRe8b9m1ktZExHxJa6rHAAZYy7BHxCOSXn/f4oWSVlb3V0q6qNm2ADSt3S/o5kTEVkmqbmfXPdH2EtvDtodHVJ6bC0D3dP3b+IhYFhFDETE0tfBFEoDuajfs22zPlaTqdntzLQHohnbDvkrS4ur+Ykn3N9MOgG5pOc5u+25JZ0k6wvZmSddLulHS921fJulFSZd0s8n93cbbTi/Wn/ncbcV6eQZ16aTVl9fWTrxmU3Hd0Vdfa/Hqnbn8iu7tB27428XF+syX/rtr294ftQx7RNRdaf+chnsB0EUcLgskQdiBJAg7kARhB5Ig7EASnOLagF/cfEax/sznytMmv7n3nWL9kp9/sVg/4avP1tZGd+4srtvKATNmFOuvfeGUYn3hofWXuT5ABxfXPfFfryzWj1vB0Nq+YM8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzj5JU+bUXnlLKy/+x+K6e1ucpNpqHH3aeS+0eP32HbDg5GL9k8s3FOs3zPmHFluovzrRmesuLa55wtLytkdbbBnvxZ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnH2SfFD9ePHQ9M5GfA/+s2nlbR8zr1jfePlRtbXzz328uO6fz15WrB99YPmc81Zj/KNRP6mzv3dEed03NrZ4dewL9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7JMU7+yqra3dNbW47unTR4r1+398T7He6nz4Tvz4/8pj3RtH6sfJJensg98q1od31x9D8NE7ue57L7Xcs9tebnu77fXjli21/bLtddXPhd1tE0CnJvMxfoWkCyZYfktELKh+Hmi2LQBNaxn2iHhE0us96AVAF3XyBd1Vtp+sPubPrHuS7SW2h20Pj6j+/14A3dVu2L8l6ROSFkjaKunmuidGxLKIGIqIoamFiw8C6K62wh4R2yJiNCL2Svq2pNOabQtA09oKu+254x5eLGl93XMBDIaW4+y275Z0lqQjbG+WdL2ks2wvkBSSNkn6SvdaHAyj27bX1q6/4svFdW/6p/J15U8pn86uf9lRPp/9hoc/W1s7fkV57vcDt71ZrM++u/zd7Nnz/rNYX/xQ/XtzvIaL66JZLcMeEYsmWHxHF3oB0EUcLgskQdiBJAg7kARhB5Ig7EASnOLagGkPloeQrju2u8ccHa+ftb3uzoXl3n549P3F+kiU9xcHb2oxroieYc8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzp7cnoPLf+9HojwddavLXB+74sX6bRfXRNPYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzJ3fYPT8tP6F2rh/sb9izA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLMnt/PSM1o847Ge9IHua7lntz3P9kO2N9h+2vbXquWzbK+2vbG6ndn9dgG0azIf4/dI+npEnCTpDElX2j5Z0rWS1kTEfElrqscABlTLsEfE1oh4vLq/U9IGSUdKWihpZfW0lZIu6lKPABqwT1/Q2f6YpFMlrZU0JyK2SmN/ECTNrllnie1h28Mj2tVhuwDaNemw2z5U0r2Sro6IHZNdLyKWRcRQRAxN1fR2egTQgEmF3fZUjQX9roj4QbV4m+25VX2upO3daRFAE1oOvdm2pDskbYiIb4wrrZK0WNKN1W15bl8MpDc/zqEWWUxmnP1MSV+S9JTtddWy6zQW8u/bvkzSi5Iu6UqHABrRMuwR8RNJrimf02w7ALqFz3BAEoQdSIKwA0kQdiAJwg4kwSmuyR358NvF+tSrphTrI9FkN+gm9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7Mn5v9YV6yt2THi1sV9adNjLxfrbvzG3tjbtpc3FddEs9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7Ci65fYvFOuLrrm1WJ/7N8/V1l5745Tyxn/6ZLmOfcKeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeScET5wt+250m6U9KvSdoraVlE3Gp7qaQ/lfRK9dTrIuKB0mt9xLPidDPx6/5kyhGHF+vT7i0fqvG94/6ttvb7Tywqrjvri68U66NvvFmsZ7Q21mhHvD7hrMuTOahmj6SvR8Tjtg+T9Jjt1VXtloi4qalGAXTPZOZn3yppa3V/p+0Nko7sdmMAmrVP/7Pb/pikUyWtrRZdZftJ28ttz6xZZ4ntYdvDI9rVWbcA2jbpsNs+VNK9kq6OiB2SviXpE5IWaGzPf/NE60XEsogYioihqZreeccA2jKpsNueqrGg3xURP5CkiNgWEaMRsVfStyWd1r02AXSqZdhtW9IdkjZExDfGLR9/2dCLJa1vvj0ATZnMt/FnSvqSpKdsr6uWXSdpke0FkkLSJklf6UJ/6LPRV18r1nd/vjw0d9LN9b8WG869vbjuZ0+8rFjnFNh9M5lv438iaaJxu+KYOoDBwhF0QBKEHUiCsANJEHYgCcIOJEHYgSRanuLaJE5xBbqrdIore3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSKKn4+y2X5H0wrhFR0h6tWcN7JtB7W1Q+5LorV1N9nZMRPzqRIWehv0DG7eHI2Kobw0UDGpvg9qXRG/t6lVvfIwHkiDsQBL9DvuyPm+/ZFB7G9S+JHprV0966+v/7AB6p997dgA9QtiBJPoSdtsX2H7G9nO2r+1HD3Vsb7L9lO11tof73Mty29ttrx+3bJbt1bY3VrcTzrHXp96W2n65eu/W2b6wT73Ns/2Q7Q22n7b9tWp5X9+7Ql89ed96/j+77SmSnpV0nqTNkh6VtCgi/qenjdSwvUnSUET0/QAM278n6S1Jd0bEJ6tlfyfp9Yi4sfpDOTMi/nJAelsq6a1+T+NdzVY0d/w045IukvQn6uN7V+jrj9SD960fe/bTJD0XEc9HxG5J90ha2Ic+Bl5EPCLp9fctXihpZXV/pcZ+WXqupreBEBFbI+Lx6v5OSe9OM97X967QV0/0I+xHSnpp3OPNGqz53kPSj2w/ZntJv5uZwJyI2CqN/fJImt3nft6v5TTevfS+acYH5r1rZ/rzTvUj7BNdH2uQxv/OjIhPSfqMpCurj6uYnElN490rE0wzPhDanf68U/0I+2ZJ88Y9PkrSlj70MaGI2FLdbpd0nwZvKupt786gW91u73M/vzRI03hPNM24BuC96+f05/0I+6OS5ts+1vY0SZdKWtWHPj7A9ozqixPZniHpfA3eVNSrJC2u7i+WdH8fe3mPQZnGu26acfX5vev79OcR0fMfSRdq7Bv5X0j66370UNPXxyU9Uf083e/eJN2tsY91Ixr7RHSZpMMlrZG0sbqdNUC9/bOkpyQ9qbFgze1Tb7+rsX8Nn5S0rvq5sN/vXaGvnrxvHC4LJMERdEAShB1IgrADSRB2IAnCDiRB2IEkCDuQxP8DoeMroAFkz54AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    plt.imshow(x_train[i])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cffa4f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e44965b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dba74e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e7c42b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed1a3aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccabd9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(x_train).reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e353baf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c3fbf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "\n",
    "def change_size(image):\n",
    "    img = array_to_img(image, scale=False) #returns PIL Image\n",
    "    img = img.resize((75, 75)) #resize image\n",
    "    img = img.convert(mode='RGB') #makes 3 channels\n",
    "    arr = img_to_array(img) #convert back to array\n",
    "    return arr.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c19f00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 75, 75, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_arr_75 = [change_size(img) for img in X_train]\n",
    "train_arr_75 = np.array(train_arr_75)\n",
    "train_arr_75.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a0cb44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rescale=1./255, #easier for network to interpret numbers in range [0,1]\n",
    "                              zoom_range=0.1,\n",
    "                              width_shift_range=0.2,\n",
    "                              height_shift_range=0.2,\n",
    "                              validation_split=0.2) # 80/20 train/val split\n",
    "\n",
    "train_generator = image_gen.flow(train_arr_75, \n",
    "                                 y_train,\n",
    "                                batch_size=32,\n",
    "                                shuffle=True,\n",
    "                                subset='training',\n",
    "                                seed=42)\n",
    "valid_generator = image_gen.flow(train_arr_75,\n",
    "                                 y_train,\n",
    "                                batch_size=16,\n",
    "                                shuffle=True,\n",
    "                                subset='validation')\n",
    "del train_arr_75 #saves RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3361ea26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68f3e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(tf.keras.applications.resnet50.ResNet50(input_shape = (75, 75, 3), \n",
    "                                include_top = False, \n",
    "                                weights = 'imagenet'))\n",
    "\n",
    "model.add(L.Flatten())\n",
    "model.add(L.Dense(128, activation='relu'))\n",
    "model.add(L.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1958bffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x24bc4d69e80>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x24bc4dabaf0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24bc4dabeb0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24bc4dabe80>,\n",
       " <keras.layers.core.activation.Activation at 0x24bff0ee130>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x24bff0eefd0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x24bff12ceb0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24bff14feb0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24bff14f3a0>,\n",
       " <keras.layers.core.activation.Activation at 0x24bff15e3a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24bff15e730>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24bff15e7f0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c12db4070>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24bff14a160>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c12db4400>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24bff12cdc0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24bff15b040>,\n",
       " <keras.layers.merge.Add at 0x24c12dbe070>,\n",
       " <keras.layers.core.activation.Activation at 0x24c12dbeac0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c12dc27c0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c12db8640>,\n",
       " <keras.layers.core.activation.Activation at 0x24c12dc8a90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c12dccd00>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c12dbed00>,\n",
       " <keras.layers.core.activation.Activation at 0x24c12dd9820>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c12dc2a90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c289c62b0>,\n",
       " <keras.layers.merge.Add at 0x24c289ca0a0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c289cab20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c289ce8e0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c289c65b0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c289d6f40>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c289c63a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c289c6460>,\n",
       " <keras.layers.core.activation.Activation at 0x24c12db8a60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c12dbe640>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24bff14f2b0>,\n",
       " <keras.layers.merge.Add at 0x24bff12c3a0>,\n",
       " <keras.layers.core.activation.Activation at 0x24bff15e820>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c289e18b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c12ddcdf0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c289ea5b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c289ea850>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c289ea730>,\n",
       " <keras.layers.core.activation.Activation at 0x24c289f4070>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c12dd5cd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c289e3df0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24bff155e50>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c289fb6d0>,\n",
       " <keras.layers.merge.Add at 0x24c3e5e60a0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c3e5e6460>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c289f4220>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c3e5e2f70>,\n",
       " <keras.layers.core.activation.Activation at 0x24c3e5e9280>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c3e5f26a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c3e5e27f0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c3e6030a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c3e603910>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c3e6087c0>,\n",
       " <keras.layers.merge.Add at 0x24c3e60e880>,\n",
       " <keras.layers.core.activation.Activation at 0x24c3e608dc0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c3e61c130>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c3e6141c0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c3e61cbb0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c3e608eb0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c3e5ff4c0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c5420f0d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c5420f9d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c54216850>,\n",
       " <keras.layers.merge.Add at 0x24c5421c040>,\n",
       " <keras.layers.core.activation.Activation at 0x24c5420d4c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c54206a00>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c5420f7f0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c3e608490>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c3e5e2ee0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c3e5e6580>,\n",
       " <keras.layers.core.activation.Activation at 0x24c12dd01c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c12dd5130>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c54222130>,\n",
       " <keras.layers.merge.Add at 0x24c3e619730>,\n",
       " <keras.layers.core.activation.Activation at 0x24c3e619250>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c54227e20>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c54227280>,\n",
       " <keras.layers.core.activation.Activation at 0x24c54230850>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c54230ac0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c54230b50>,\n",
       " <keras.layers.core.activation.Activation at 0x24c5423b220>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c5421ff70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c542335e0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c54222a90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c69e21970>,\n",
       " <keras.layers.merge.Add at 0x24c69e2c310>,\n",
       " <keras.layers.core.activation.Activation at 0x24c69e2c850>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c69e322e0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c69e21df0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c69e38d00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c69e26460>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c69e26ca0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c69e46280>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c69e46b80>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c69e4da30>,\n",
       " <keras.layers.merge.Add at 0x24c69e53220>,\n",
       " <keras.layers.core.activation.Activation at 0x24c69e428b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c69e5f370>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c69e573a0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c69e5f700>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c7fa449a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c7fa44310>,\n",
       " <keras.layers.core.activation.Activation at 0x24c7fa54340>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c7fa54c40>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c69e4d100>,\n",
       " <keras.layers.merge.Add at 0x24c69e32130>,\n",
       " <keras.layers.core.activation.Activation at 0x24c69e264f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c54230280>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c69e570d0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c12dac2e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c54230e80>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c5421fc10>,\n",
       " <keras.layers.core.activation.Activation at 0x24c7fa5b130>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c7fa5ba30>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c7fa4d8b0>,\n",
       " <keras.layers.merge.Add at 0x24c7fa580a0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c7fa4deb0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c7fa631f0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c7fa5e2b0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c7fa63ca0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c7fa5e430>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c69e415b0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c7fa6fc70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c7fa73490>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c7fa79940>,\n",
       " <keras.layers.merge.Add at 0x24c7fa7f130>,\n",
       " <keras.layers.core.activation.Activation at 0x24c7fa7fe20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c9566a280>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c956710a0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c9566ad60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c95676370>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c9567abe0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c95676b20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c9566a490>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c9568d2b0>,\n",
       " <keras.layers.merge.Add at 0x24c956852e0>,\n",
       " <keras.layers.core.activation.Activation at 0x24c95665220>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c95685910>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c95685970>,\n",
       " <keras.layers.core.activation.Activation at 0x24c95698970>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24cab284fa0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c95685190>,\n",
       " <keras.layers.core.activation.Activation at 0x24c956851c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c95694760>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c7fa73820>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c95676f10>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c7fa699d0>,\n",
       " <keras.layers.merge.Add at 0x24c3e5e6520>,\n",
       " <keras.layers.core.activation.Activation at 0x24bff15b3a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24cab28b3d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c7fa69fd0>,\n",
       " <keras.layers.core.activation.Activation at 0x24cab28bd60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24c54216910>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24c956979d0>,\n",
       " <keras.layers.core.activation.Activation at 0x24cab292370>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24cab292c70>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24cab294ac0>,\n",
       " <keras.layers.merge.Add at 0x24cab2972b0>,\n",
       " <keras.layers.core.activation.Activation at 0x24cab292f70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24cab2a2400>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24cab29b640>,\n",
       " <keras.layers.core.activation.Activation at 0x24cab2a9490>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24cab2a2be0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24cab2a2730>,\n",
       " <keras.layers.core.activation.Activation at 0x24cab2b2f70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x24cab2b96a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x24cab2bebb0>,\n",
       " <keras.layers.merge.Add at 0x24cc0ea33a0>,\n",
       " <keras.layers.core.activation.Activation at 0x24cc0ea3160>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "203093a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[0].layers:\n",
    "    if layer.name == 'conv5_block1_0_conv':\n",
    "        break\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ad2b810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f15dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 4541s 3s/step - loss: 0.1537 - accuracy: 0.9552 - val_loss: 0.0838 - val_accuracy: 0.9761\n",
      "Epoch 2/5\n",
      " 101/1500 [=>............................] - ETA: 1:28:04 - loss: 0.0726 - accuracy: 0.9796"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, validation_data=valid_generator, epochs=5, \n",
    "          steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
    "         validation_steps=valid_generator.n//valid_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ffc76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
